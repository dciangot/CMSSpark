{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of using CMSSpark for analysis workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT!!!\n",
    "# ------------\n",
    "# Before running this notebook please click on star icon (if it is there) to connect to Spark cluster\n",
    "# it setups spark context variables used in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analyzer.ipynb\t\tws_17_07.pkl  ws_18_11.pkl\n",
      "cache_emulator.ipynb\tws_17_08.pkl  ws_18_12.pkl\n",
      "condor_20180101\t\tws_17_09.pkl  ws_201801.pkl\n",
      "dataset_producer.ipynb\tws_17_10.pkl  ws_all_18.pkl.gz\n",
      "env.sh\t\t\tws_17_11.pkl  ws_T2_DE_17.pkl.gz\n",
      "panduplizer.ipynb\tws_17_12.pkl  ws_T2_DE_18.pkl.gz\n",
      "plot.pdf\t\tws_18_02.pkl  ws_T2_ES_17.pkl.gz\n",
      "spark-warehouse\t\tws_18_03.pkl  ws_T2_ES_18.pkl.gz\n",
      "wdir\t\t\tws_18_04.pkl  ws_T2_FR_17.pkl.gz\n",
      "ws_17_01.pkl\t\tws_18_05.pkl  ws_T2_FR_18.pkl.gz\n",
      "ws_17_02.pkl\t\tws_18_06.pkl  ws_T2_IT_17.pkl.gz\n",
      "ws_17_03.pkl\t\tws_18_07.pkl  ws_T2_IT_18.pkl.gz\n",
      "ws_17_04.pkl\t\tws_18_08.pkl  ws_T2_US_17.pkl.gz\n",
      "ws_17_05.pkl\t\tws_18_09.pkl  ws_T2_US_18.pkl.gz\n",
      "ws_17_06.pkl\t\tws_18_10.pkl  xdf_raw_jan_2018.pkl.gz\n",
      "--2019-05-06 12:50:33--  https://my.pcloud.com/publink/show?code=XZwzn97ZIoG4isDNO3b6SrTEUfQ1Y4E6bp9k\n",
      "Resolving my.pcloud.com (my.pcloud.com)... 74.120.8.226, 74.120.9.90, 74.120.9.89, ...\n",
      "Connecting to my.pcloud.com (my.pcloud.com)|74.120.8.226|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 43263 (42K) [text/html]\n",
      "Saving to: ‘./avro-mapred.jar’\n",
      "\n",
      "100%[======================================>] 43,263      --.-K/s   in 0.1s    \n",
      "\n",
      "2019-05-06 12:50:33 (338 KB/s) - ‘./avro-mapred.jar’ saved [43263/43263]\n",
      "\n",
      "--2019-05-06 12:50:34--  https://my.pcloud.com/publink/show?code=XZazn97Z9aGq81aVgBLcHi9LBNqryuqs310V\n",
      "Resolving my.pcloud.com (my.pcloud.com)... 74.120.8.14, 74.120.8.13, 74.120.8.226, ...\n",
      "Connecting to my.pcloud.com (my.pcloud.com)|74.120.8.14|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 43363 (42K) [text/html]\n",
      "Saving to: ‘./spark-csv-assembly-1.4.0.jar’\n",
      "\n",
      "100%[======================================>] 43,363      --.-K/s   in 0.1s    \n",
      "\n",
      "2019-05-06 12:50:34 (306 KB/s) - ‘./spark-csv-assembly-1.4.0.jar’ saved [43363/43363]\n",
      "\n",
      "--2019-05-06 12:50:34--  http://cmsdoc.cern.ch/~dciangot/spark-examples.jar\n",
      "Resolving cmsdoc.cern.ch (cmsdoc.cern.ch)... 128.142.152.37, 128.142.132.87\n",
      "Connecting to cmsdoc.cern.ch (cmsdoc.cern.ch)|128.142.152.37|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 19914970 (19M) [application/x-java-archive]\n",
      "Saving to: ‘./spark-examples-1.6.0-cdh5.7.6-hadoop2.6.0-cdh5.7.6.jar’\n",
      "\n",
      "100%[======================================>] 19,914,970  21.3MB/s   in 0.9s   \n",
      "\n",
      "2019-05-06 12:50:35 (21.3 MB/s) - ‘./spark-examples-1.6.0-cdh5.7.6-hadoop2.6.0-cdh5.7.6.jar’ saved [19914970/19914970]\n",
      "\n",
      "--2019-05-06 12:50:35--  https://github.com/dmwm/CMSSpark/archive/master.zip\n",
      "Resolving github.com (github.com)... 140.82.118.3\n",
      "Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://codeload.github.com/dmwm/CMSSpark/zip/master [following]\n",
      "--2019-05-06 12:50:36--  https://codeload.github.com/dmwm/CMSSpark/zip/master\n",
      "Resolving codeload.github.com (codeload.github.com)... 192.30.253.120\n",
      "Connecting to codeload.github.com (codeload.github.com)|192.30.253.120|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [application/zip]\n",
      "Saving to: ‘./master.zip’\n",
      "\n",
      "    [    <=>                                ] 2,505,979   2.98MB/s   in 0.8s   \n",
      "\n",
      "2019-05-06 12:50:37 (2.98 MB/s) - ‘./master.zip’ saved [2505979]\n",
      "\n",
      "Archive:  ./master.zip\n",
      "7f72d51f1a9c58aa28483483cfbbd412264425e1\n",
      "   creating: CMSSpark-master/\n",
      "  inflating: CMSSpark-master/.gitignore  \n",
      "  inflating: CMSSpark-master/LICENSE  \n",
      "  inflating: CMSSpark-master/README.md  \n",
      "  inflating: CMSSpark-master/README_Leftovers.md  \n",
      "   creating: CMSSpark-master/bin/\n",
      "  inflating: CMSSpark-master/bin/cron4aggregation  \n",
      "  inflating: CMSSpark-master/bin/cron4dbs_condor  \n",
      "  inflating: CMSSpark-master/bin/cron4dbs_condor_df  \n",
      "  inflating: CMSSpark-master/bin/cron4dbs_events  \n",
      "  inflating: CMSSpark-master/bin/cron4phedex  \n",
      "  inflating: CMSSpark-master/bin/cron4phedex_df  \n",
      "  inflating: CMSSpark-master/bin/get_dbs_condor.sh  \n",
      "  inflating: CMSSpark-master/bin/get_dbs_events.sh  \n",
      "  inflating: CMSSpark-master/bin/run_aggregation  \n",
      "  inflating: CMSSpark-master/bin/run_dbs_condor.sh  \n",
      "  inflating: CMSSpark-master/bin/run_dbs_events.sh  \n",
      "  inflating: CMSSpark-master/bin/run_phedex.sh  \n",
      "  inflating: CMSSpark-master/bin/run_spark  \n",
      "   creating: CMSSpark-master/doc/\n",
      "  inflating: CMSSpark-master/doc/CMSSpark.pdf  \n",
      "  inflating: CMSSpark-master/doc/CMSSpark.png  \n",
      "   creating: CMSSpark-master/etc/\n",
      "  inflating: CMSSpark-master/etc/conf.json  \n",
      "  inflating: CMSSpark-master/etc/example.csv  \n",
      "  inflating: CMSSpark-master/etc/log4j.properties  \n",
      "  inflating: CMSSpark-master/setup_lxplus.sh  \n",
      "   creating: CMSSpark-master/src/\n",
      "   creating: CMSSpark-master/src/Go/\n",
      "  inflating: CMSSpark-master/src/Go/mergePhedex.go  \n",
      "   creating: CMSSpark-master/src/bash/\n",
      "  inflating: CMSSpark-master/src/bash/dbs_phedex_stats.sh  \n",
      "  inflating: CMSSpark-master/src/bash/download_and_concat.sh  \n",
      "   creating: CMSSpark-master/src/bash/report_campaigns/\n",
      "  inflating: CMSSpark-master/src/bash/report_campaigns/aggregate  \n",
      "  inflating: CMSSpark-master/src/bash/report_campaigns/aggregate_campaign_tier  \n",
      "  inflating: CMSSpark-master/src/bash/report_campaigns/aggregate_campaigns  \n",
      "   creating: CMSSpark-master/src/bash/report_leftovers/\n",
      "  inflating: CMSSpark-master/src/bash/report_leftovers/aggregate_leftovers  \n",
      "   creating: CMSSpark-master/src/bash/report_tiers/\n",
      "  inflating: CMSSpark-master/src/bash/report_tiers/aggregate  \n",
      "  inflating: CMSSpark-master/src/bash/report_tiers/aggregate_dbs  \n",
      "  inflating: CMSSpark-master/src/bash/report_tiers/aggregate_phedex  \n",
      "  inflating: CMSSpark-master/src/bash/reports_init  \n",
      "   creating: CMSSpark-master/src/notebooks/\n",
      "  inflating: CMSSpark-master/src/notebooks/CMSSparkExample.ipynb  \n",
      "   creating: CMSSpark-master/src/python/\n",
      "   creating: CMSSpark-master/src/python/CMSSpark/\n",
      "  inflating: CMSSpark-master/src/python/CMSSpark/__init__.py  \n",
      "  inflating: CMSSpark-master/src/python/CMSSpark/aso_stats.py  \n",
      "  inflating: CMSSpark-master/src/python/CMSSpark/cern_monit.py  \n",
      "  inflating: CMSSpark-master/src/python/CMSSpark/conf.py  \n",
      "  inflating: CMSSpark-master/src/python/CMSSpark/data_aggregation.py  \n",
      "  inflating: CMSSpark-master/src/python/CMSSpark/data_aggregation_plots.py  \n",
      "  inflating: CMSSpark-master/src/python/CMSSpark/data_collection.py  \n",
      "  inflating: CMSSpark-master/src/python/CMSSpark/dates.py  \n",
      "  inflating: CMSSpark-master/src/python/CMSSpark/dbs_aaa.py  \n",
      "  inflating: CMSSpark-master/src/python/CMSSpark/dbs_adler.py  \n",
      "  inflating: CMSSpark-master/src/python/CMSSpark/dbs_block_lumis.py  \n",
      "  inflating: CMSSpark-master/src/python/CMSSpark/dbs_cmssw.py  \n",
      "  inflating: CMSSpark-master/src/python/CMSSpark/dbs_condor.py  \n",
      "  inflating: CMSSpark-master/src/python/CMSSpark/dbs_eos.py  \n",
      "  inflating: CMSSpark-master/src/python/CMSSpark/dbs_events.py  \n",
      "  inflating: CMSSpark-master/src/python/CMSSpark/dbs_jm.py  \n",
      "  inflating: CMSSpark-master/src/python/CMSSpark/dbs_lfn.py  \n",
      "  inflating: CMSSpark-master/src/python/CMSSpark/dbs_phedex.py  \n",
      "  inflating: CMSSpark-master/src/python/CMSSpark/fts_aso.py  \n",
      "  inflating: CMSSpark-master/src/python/CMSSpark/getCSV.py  \n",
      "  inflating: CMSSpark-master/src/python/CMSSpark/jm_stats.py  \n",
      "  inflating: CMSSpark-master/src/python/CMSSpark/mergePhedex.py  \n",
      "  inflating: CMSSpark-master/src/python/CMSSpark/phedex.py  \n",
      "  inflating: CMSSpark-master/src/python/CMSSpark/phedex_agg.py  \n",
      "   creating: CMSSpark-master/src/python/CMSSpark/reports/\n",
      "  inflating: CMSSpark-master/src/python/CMSSpark/reports/aggregate_campaign_tier.py  \n",
      "  inflating: CMSSpark-master/src/python/CMSSpark/reports/aggregate_campaigns.py  \n",
      "  inflating: CMSSpark-master/src/python/CMSSpark/reports/aggregate_dbs.py  \n",
      "  inflating: CMSSpark-master/src/python/CMSSpark/reports/aggregate_leftovers.py  \n",
      "  inflating: CMSSpark-master/src/python/CMSSpark/reports/aggregate_phedex.py  \n",
      "  inflating: CMSSpark-master/src/python/CMSSpark/reports/report_builder.py  \n",
      "  inflating: CMSSpark-master/src/python/CMSSpark/reports/visualize_campaigns.py  \n",
      "  inflating: CMSSpark-master/src/python/CMSSpark/reports/visualize_leftovers.py  \n",
      "  inflating: CMSSpark-master/src/python/CMSSpark/reports/visualize_tiers.py  \n",
      "  inflating: CMSSpark-master/src/python/CMSSpark/schemas.py  \n",
      "  inflating: CMSSpark-master/src/python/CMSSpark/spark_utils.py  \n",
      "  inflating: CMSSpark-master/src/python/CMSSpark/stats.py  \n",
      "  inflating: CMSSpark-master/src/python/CMSSpark/utils.py  \n",
      "  inflating: CMSSpark-master/src/python/CMSSpark/wmarchive.py  \n",
      "   creating: CMSSpark-master/static/\n",
      "  inflating: CMSSpark-master/static/LICENSE  \n",
      "  inflating: CMSSpark-master/static/README.md  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analyzer.ipynb\t\tws_17_07.pkl  ws_18_11.pkl\n",
      "cache_emulator.ipynb\tws_17_08.pkl  ws_18_12.pkl\n",
      "condor_20180101\t\tws_17_09.pkl  ws_201801.pkl\n",
      "dataset_producer.ipynb\tws_17_10.pkl  ws_all_18.pkl.gz\n",
      "env.sh\t\t\tws_17_11.pkl  ws_T2_DE_17.pkl.gz\n",
      "panduplizer.ipynb\tws_17_12.pkl  ws_T2_DE_18.pkl.gz\n",
      "plot.pdf\t\tws_18_02.pkl  ws_T2_ES_17.pkl.gz\n",
      "spark-warehouse\t\tws_18_03.pkl  ws_T2_ES_18.pkl.gz\n",
      "wdir\t\t\tws_18_04.pkl  ws_T2_FR_17.pkl.gz\n",
      "ws_17_01.pkl\t\tws_18_05.pkl  ws_T2_FR_18.pkl.gz\n",
      "ws_17_02.pkl\t\tws_18_06.pkl  ws_T2_IT_17.pkl.gz\n",
      "ws_17_03.pkl\t\tws_18_07.pkl  ws_T2_IT_18.pkl.gz\n",
      "ws_17_04.pkl\t\tws_18_08.pkl  ws_T2_US_17.pkl.gz\n",
      "ws_17_05.pkl\t\tws_18_09.pkl  ws_T2_US_18.pkl.gz\n",
      "ws_17_06.pkl\t\tws_18_10.pkl  xdf_raw_jan_2018.pkl.gz\n",
      "avro-mapred.jar  spark-csv-assembly-1.4.0.jar\n",
      "CMSSpark\t spark-examples-1.6.0-cdh5.7.6-hadoop2.6.0-cdh5.7.6.jar\n",
      "master.zip\n"
     ]
    }
   ],
   "source": [
    "# execute this cell which downloads required libraries and put them in place\n",
    "import os\n",
    "with open('env.sh', 'w') as ostream:\n",
    "    ostream.write(\"\"\"#!/bin/bash\n",
    "wdir=$PWD/wdir\n",
    "if [ -d $wdir ]; then\n",
    "    rm -rf $wdir\n",
    "fi\n",
    "mkdir -p $wdir\n",
    "cd $wdir\n",
    "wget https://my.pcloud.com/publink/show?code=XZwzn97ZIoG4isDNO3b6SrTEUfQ1Y4E6bp9k -O ./avro-mapred.jar\n",
    "wget https://my.pcloud.com/publink/show?code=XZazn97Z9aGq81aVgBLcHi9LBNqryuqs310V -O ./spark-csv-assembly-1.4.0.jar\n",
    "wget http://cmsdoc.cern.ch/~dciangot/spark-examples.jar -O ./spark-examples-1.6.0-cdh5.7.6-hadoop2.6.0-cdh5.7.6.jar\n",
    "wget https://github.com/dmwm/CMSSpark/archive/master.zip -O ./master.zip\n",
    "unzip ./master.zip 2> /dev/null\n",
    "mv CMSSpark-master CMSSpark\"\"\")\n",
    "!ls\n",
    "!source ./env.sh\n",
    "!ls\n",
    "!cd wdir; ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include the CMSSpark python in the sys.path\n",
    "import os,sys\n",
    "sys.path.append(os.path.join(os.path.expanduser(\"~\"), 'SWAN_projects/CMSSpark/src/python'))\n",
    "#print(sys.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##working_set_day.head(10)\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "#['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']\n",
    "for i in ['03', '04']:#, '03', '04']:\n",
    "    data = sqlContext.read.parquet(\"hdfs://analytix/cms/users/dciangot/ws_classAds_19_%s\" % i)\n",
    "    data.toPandas().to_pickle(\"./ws_19_%s.pkl\" % i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "sparkconnect": {
   "bundled_options": [
    "CMSSpark"
   ],
   "list_of_options": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
